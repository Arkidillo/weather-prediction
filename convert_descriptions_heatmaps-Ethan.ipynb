{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ethan Klein\n",
    "# Converts all weather descriptions to categorical variables - then focuses them into 6 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "\n",
    "#load the weather dataset\n",
    "weather_description = pd.read_csv(\"weather_description.csv\")\n",
    "\n",
    "desc = {}\n",
    "counter = 0\n",
    "for loc in weather_description:\n",
    "    if (loc != 'datetime'):\n",
    "        for elem in weather_description[loc].unique():\n",
    "            if (elem not in desc):\n",
    "                desc[elem] = counter\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "#print(desc)\n",
    "\n",
    "weather_description = weather_description.replace(desc)\n",
    "\n",
    "#reduce the number of categories from 54 to around 6\n",
    "#category 0 = nan\n",
    "#category 1 = clear sky\n",
    "#category 2 = clouds\n",
    "#category 3 = light rain/snow \n",
    "#category 4 = heavy rain/snow/storm\n",
    "\n",
    "#storing the 54 different description variables in different sub categories\n",
    "category_0 = [0]\n",
    "category_1 = [3]\n",
    "category_2 = [2, 5, 6, 7, 11, 21, 26, 27, 28, 42, 44, 45]\n",
    "category_3 = [1, 4, 8, 9, 10, 12, 15, 16, 18, 19, 23, 31, 32, 33, 34, 35, 38, 39, 43, 51, 52]\n",
    "category_4 = [13, 14, 17, 20, 22, 24, 29, 30, 36, 37, 40, 41, 46, 47, 25, 48, 49, 50, 53, 54]\n",
    "\n",
    "weather_description = weather_description.replace(category_0, 0)\n",
    "weather_description = weather_description.replace(category_1, 1)\n",
    "weather_description = weather_description.replace(category_2, 2)\n",
    "weather_description = weather_description.replace(category_3, 3)\n",
    "weather_description = weather_description.replace(category_4, 4)\n",
    "\n",
    "#for loc in weather_description:\n",
    "#    if (loc != \"datetime\"):\n",
    "#        for elem in weather_description[loc].unique():\n",
    "#            if elem in category_0:\n",
    "#                weather_description.replace(elem, 0)\n",
    "#            if elem in category_1:\n",
    "#                weather_description.replace(elem, 1)\n",
    "#            if elem in category_2:\n",
    "#                weather_description.replace(elem, 2)\n",
    "#            if elem in category_3:\n",
    "#                weather_description.replace(elem, 3)\n",
    "#            if elem in category_4:\n",
    "#                weather_description.replace(elem, 4)\n",
    "#print(weather_description)\n",
    "\n",
    "weather_description.to_csv(\"converted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data analytics - and heat maps \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e894c5e3b1343d2ac3a9b06771f71c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First heat map - displays all the cities where weather data was gathered from\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "import pandas as pd\n",
    "\n",
    "gmaps.configure(api_key=\"AIzaSyBO3ZiyID1_Y-ia_G19XVI4Y8w_g4mCMVM\") # Google API key\n",
    "\n",
    "\n",
    "#read the csv\n",
    "df_all_cities = pd.read_csv(\"city_attributes.csv\")\n",
    "\n",
    "#drop the city and country headers\n",
    "df_all_cities = df_all_cities.drop(['City', 'Country'], axis=1)\n",
    "\n",
    "#convert dataframe into numpy array to generate heatmap\n",
    "subset_nparray = df_all_cities[['Latitude', 'Longitude']]\n",
    "\n",
    "#convert to a single array of tuples\n",
    "tuples_array = [tuple(x) for x in subset_nparray.values]\n",
    "\n",
    "\n",
    "heatmap_initial_cities = gmaps.Map()\n",
    "heatmap_initial_cities.add_layer(gmaps.Heatmap(data=tuples_array))\n",
    "heatmap_initial_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to read rows of csv into correct format\n",
    "def _read_rows(f, column_types):\n",
    "    f.readline()  \n",
    "    reader = csv.reader(codecs.iterdecode(f, \"utf-8\"))\n",
    "    rows = []\n",
    "    for row in reader:\n",
    "        typed_row = [\n",
    "            column_type(cell) for column_type, cell in zip(column_types, row)\n",
    "        ]\n",
    "        rows.append(tuple(typed_row))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phoenix': 321.22000000000003, 'Tel Aviv District': 320.93000000000001, 'Haifa': 320.93000000000001, 'Eilat': 320.14999999999998, 'Las Vegas': 318.63999999999999}\n",
      "                 City   Latitude   Longitude\n",
      "6           Las Vegas  36.174969 -115.137222\n",
      "7             Phoenix  33.448380 -112.074043\n",
      "31  Tel Aviv District  32.083328   34.799999\n",
      "32              Eilat  29.558050   34.948212\n",
      "33              Haifa  32.815559   34.989170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e1b206bac044b497ecc0500c518fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# second heat map - top 5 hottest days - where they occured\n",
    "# extract data from each city - get its top 100 hottest days, then compare all the cities against each other\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "gmaps.configure(api_key=\"AIzaSyBO3ZiyID1_Y-ia_G19XVI4Y8w_g4mCMVM\") # Google API key\n",
    "\n",
    "# read the csv - cities & temps\n",
    "df_cities = pd.read_csv(\"city_attributes.csv\")\n",
    "df_temps = pd.read_csv(\"temperature.csv\")\n",
    "\n",
    "# dropping the datatime column\n",
    "df_temps = df_temps.drop(['datetime'], axis=1)\n",
    "df_cities = df_cities.drop(['Country'], axis=1)\n",
    "\n",
    "# getting a list of all the headers (cities)\n",
    "temp_headers = list(df_temps.columns.values)\n",
    "\n",
    "# dict containing the cities and their hottest temps\n",
    "hottest_city_temp = {}\n",
    "\n",
    "hottest_temp = 0\n",
    "\n",
    "# iterate through cities, and find their hottest days\n",
    "for city in temp_headers:\n",
    "    for temp in df_temps[city]:\n",
    "        if temp > hottest_temp:\n",
    "            hottest_temp = temp\n",
    "    hottest_city_temp[city] = hottest_temp\n",
    "    hottest_temp = 0\n",
    "\n",
    "#get the top 5 hottest cities from the dictionary\n",
    "top_five_hottest = dict(sorted(hottest_city_temp.items(), key=operator.itemgetter(1), reverse=True)[:5])\n",
    "\n",
    "print(top_five_hottest)\n",
    "\n",
    "#convert dataframe into numpy array to generate heatmap\n",
    "#subset_nparray = df_cities[['Latitude', 'Longitude']]\n",
    "\n",
    "counter = 0\n",
    "for city in df_cities.iterrows():\n",
    "    if city[1][0] not in top_five_hottest:\n",
    "        df_cities = df_cities.drop([counter])\n",
    "    counter += 1\n",
    "        \n",
    "print(df_cities)\n",
    "\n",
    "df_cities = df_cities.drop(['City'], axis=1)\n",
    "\n",
    "#convert dataframe into numpy array to generate heatmap\n",
    "subset_nparray = df_cities[['Latitude', 'Longitude']]\n",
    "\n",
    "#convert to a single array of tuples\n",
    "tuples_array = [tuple(x) for x in subset_nparray.values]\n",
    "\n",
    "\n",
    "heatmap_initial_cities = gmaps.Map()\n",
    "heatmap_initial_cities.add_layer(gmaps.Heatmap(data=tuples_array))\n",
    "heatmap_initial_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
