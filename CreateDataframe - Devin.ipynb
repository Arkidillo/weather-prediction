{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['humidity', 'pressure', 'temperature', 'converted', 'wind_direction', 'wind_speed']\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import *\n",
    "import calendar\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create constants for filenames\n",
    "\n",
    "city_attrib_file = 'city_attributes.csv'\n",
    "humidity_file = 'humidity.csv'\n",
    "pressure_file = 'pressure.csv'\n",
    "temperature_file = 'temperature.csv'\n",
    "weather_description_file = 'converted.csv'\n",
    "wind_direction_file = 'wind_direction.csv'\n",
    "wind_speed_file = 'wind_speed.csv'\n",
    "\n",
    "training_date_range = ('2013-10-2', '2016-12-31')\n",
    "test_date_range = ('2017-1-1', '2017-11-30')\n",
    "# List of all independent variable files we are pulling data from\n",
    "attrib_files = [humidity_file, pressure_file, temperature_file, weather_description_file, wind_direction_file, wind_speed_file]\n",
    "# List of all independent variables (not files)\n",
    "attribs = []\n",
    "for attrib_file in attrib_files:\n",
    "    attribs.append(attrib_file[:-4])\n",
    "\n",
    "\n",
    "# Create lists of 12 cities\n",
    "cities = list(pd.read_csv(humidity_file, sep=',').columns.values)\n",
    "cities.remove('datetime')\n",
    "\n",
    "devin_cities = cities[:12]\n",
    "ethan_cities = cities[12:24]\n",
    "phil_cities = cities[24:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib_dfs = []\n",
    "for file in attrib_files:\n",
    "    attrib_dfs.append(pd.read_csv(file, sep=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that will form our training and test dataset \n",
    "\n",
    "# Args:\n",
    "    # df = dataframe to append to\n",
    "    # city_name = name of city we are creating the dataset for\n",
    "    # date = date we are trying to predict (mm/dd/yyyy) as a str\n",
    "# Return:\n",
    "    # new df with added row\n",
    "def create_data_df_for_city_date(df, city_name, date):\n",
    "    datetime_obj = datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    new_data_row = []\n",
    "    \n",
    "    # For each independent attribute, get each feature\n",
    "    for atrrib_df in attrib_dfs:\n",
    "        # add the new tuple to the end of the list (row)\n",
    "        attrib_1yr_3days_values = get_1yr_3days_attrib(city_name, datetime_obj, atrrib_df)\n",
    "        for val in attrib_1yr_3days_values:\n",
    "            new_data_row.append(val)\n",
    "        \n",
    "        \n",
    "    # For each dependent attribute, get each feature (just 1 day)\n",
    "    for atrrib_df in attrib_dfs:\n",
    "        new_data_row.append(get_today_attrib(city_name, datetime_obj, atrrib_df))\n",
    "        \n",
    "    \n",
    "    df.loc[len(df)] = new_data_row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get 1 year ago and 3 days ago data from the date\n",
    "    # for a given attribute (temp/pres/humidity...etc)\n",
    "    \n",
    "# Args:\n",
    "    # city_name = name of city you want the data of\n",
    "    # date = the current date, from which you want 1 year ago and the past 3 days\n",
    "    # csv_file = the attribute you want to get\n",
    "    \n",
    "# Returns:\n",
    "    # tuple of (1yr,3days,2days,1day)\n",
    "def get_1yr_3days_attrib(city_name, date, attrib_df):\n",
    "    ret = []\n",
    "    \n",
    "    year_1_date = date - timedelta(days=365)\n",
    "    ret.append(get_avg(attrib_df, city_name, year_1_date))\n",
    "    \n",
    "    \n",
    "    day_3_date = date - timedelta(days=3)\n",
    "    ret.append(get_avg(attrib_df, city_name, day_3_date))\n",
    "    \n",
    "    day_2_date = date - timedelta(days=2)\n",
    "    ret.append(get_avg(attrib_df, city_name, day_2_date))\n",
    "    \n",
    "    day_1_date = date - timedelta(days=1)\n",
    "    ret.append(get_avg(attrib_df, city_name, day_1_date))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's attribute (avg'ed) based on city and csv_file\n",
    "# Args:\n",
    "    # city_name = name of city you want the data of\n",
    "    # date = the current date, from which you want 1 year ago and the past 3 days\n",
    "    # csv_file = the attribute you want to get\n",
    "# Returns:\n",
    "    # the avg of the attribute for the given day and city\n",
    "def get_today_attrib(city_name, date, attrib_df):\n",
    "    return get_avg(attrib_df, city_name, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(dataframe, city, date):\n",
    "    strdate = date.strftime(\"%Y-%m-%d\")\n",
    "    daily = dataframe[['datetime', city]].copy() #create dataframe of just datetimes and that city \n",
    "    day = daily[daily['datetime'].str.contains(strdate)]   #filter above dataframe for a specific day\n",
    "    valGood = day.dropna()\n",
    "    vals = list(valGood[city])     #create list of all temps for that day\n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all dates within the date_range\n",
    "def dates_list(date_range):\n",
    "    dates = []\n",
    "    date1 = datetime.strptime(date_range[0], \"%Y-%m-%d\")\n",
    "    date2 = datetime.strptime(date_range[1], \"%Y-%m-%d\")\n",
    "    delta = date2 - date1       # timedelta\n",
    "    for i in range(delta.days + 1):\n",
    "        newDate = (date1 + timedelta(days=i))\n",
    "        dates.append(newDate.strftime('%Y-%m-%d'))\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all possible combinations of cities and dates\n",
    "def get_date_city_combo(city, date_range):\n",
    "    #create city + date tuples in a list\n",
    "    city_date_combo = []\n",
    "    for date in date_range:\n",
    "        tup = (city, date)\n",
    "        city_date_combo.append(tup)\n",
    "    return city_date_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all city names\n",
    "def get_all_cities():\n",
    "    cities = list(humidity.columns.values)\n",
    "    cities.remove('datetime')\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the df with all independent + dependent variables for given city\n",
    "def create_training_df_for_city(city):\n",
    "    columns = []\n",
    "    for index in attrib_files:\n",
    "        index = index.rstrip('.csv')\n",
    "        columns.append(index + '_1year')\n",
    "        columns.append(index + '_3days')\n",
    "        columns.append(index + '_2days')\n",
    "        columns.append(index + '_1days')\n",
    "    for index in attrib_files:\n",
    "        columns.append(index + '_today')\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    city_date_combos = get_date_city_combo(city, dates_list(training_date_range))\n",
    "    for city_date in city_date_combos:\n",
    "        df = create_data_df_for_city_date(df, city_date[0], city_date[1])\n",
    "        print(df)\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Create the df with all independent variables for given city\n",
    "def create_test_df_for_city(city):\n",
    "    columns = []\n",
    "    for index in attrib_files:\n",
    "        index = index.rstrip('.csv')\n",
    "        columns.append(index + '_1year')\n",
    "        columns.append(index + '_3days')\n",
    "        columns.append(index + '_2days')\n",
    "        columns.append(index + '_1days')\n",
    "    for index in attrib_files:\n",
    "        columns.append(index + '_today')\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    city_date_combos = get_date_city_combo(city, dates_list(test_date_range))\n",
    "    for city_date in city_date_combos:\n",
    "        df = create_data_df_for_city_date(df, city_date[0], city_date[1])\n",
    "        print(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trained fatality prediction model for the given road\n",
    "def create_model(training_df, attrib):\n",
    "    # Model types\n",
    "    model_types = [LinearRegression(), SVR(), Ridge()]\n",
    "\n",
    "    # Find the index of the attribute we are talking about, by comparing to the attribute list we have\n",
    "    attrib_file = attrib + '.csv'\n",
    "    attrib_index = attrib_files.index(attrib_file)\n",
    "    # Create the training and test data sets, X=all rows but last 6, y=the attrib column we are interested in\n",
    "    X = training_df.iloc[:, :-6]\n",
    "    y = training_df.iloc[:, -attrib_index]\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.1)\n",
    "    \n",
    "    train_y = np.ravel(train_y)\n",
    "    test_y = np.ravel(test_y)\n",
    "    \n",
    "    # Calculate k and n for AIC BIC calculation\n",
    "    n = training_df.shape[0]\n",
    "    k = X.shape[1] + 1\n",
    "    \n",
    "    # Run through all models and fit the data\n",
    "    model_metrics = []\n",
    "    for model in model_types:\n",
    "        model.fit(train_X, train_y)\n",
    "        # Associate the accuracy score to the given model\n",
    "        cv_scores = cross_val_score(model, test_X, test_y, cv=10, scoring='mean_squared_error')\n",
    "        # Ensure each metric is positive before taking the mean\n",
    "        for index in range(0, cv_scores.size):\n",
    "            cv_scores[index] = abs(cv_scores[index])\n",
    "        MSE = cv_scores.mean()\n",
    "        \n",
    "        aic = (2 * k) + n * np.log(MSE)\n",
    "        bic = k * np.log(n) + n * np.log(MSE)\n",
    "        model_metrics.append((aic + bic)/2)\n",
    "        \n",
    "    best_metric = min(model_metrics)\n",
    "    print('Best AIC + BIC avg: ', best_metric)\n",
    "    best_model_index = model_metrics.index(best_metric)\n",
    "    \n",
    "    return model_types[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for each attribute for the given city\n",
    "def create_all_attrib_models(city):\n",
    "    training_df = pd.read_csv(city + '.csv')\n",
    "    models = []\n",
    "    for attrib in attribs:\n",
    "        models.append(creat_model(training_df, attrib))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   humidity_1year  humidity_3days  humidity_2days  humidity_1days  \\\n",
      "0          97.375       84.041667       90.708333       95.416667   \n",
      "\n",
      "   pressure_1year  pressure_3days  pressure_2days  pressure_1days  \\\n",
      "0     1023.708333         1021.75     1021.666667     1021.666667   \n",
      "\n",
      "   temperature_1year  temperature_3days          ...           \\\n",
      "0         270.311755         275.364583          ...            \n",
      "\n",
      "   wind_speed_1year  wind_speed_3days  wind_speed_2days  wind_speed_1days  \\\n",
      "0          1.666667          3.083333              2.25              1.75   \n",
      "\n",
      "   humidity.csv_today  pressure.csv_today  temperature.csv_today  \\\n",
      "0           84.333333            1007.625              274.28125   \n",
      "\n",
      "   converted.csv_today  wind_direction.csv_today  wind_speed.csv_today  \n",
      "0                2.875                134.583333              4.083333  \n",
      "\n",
      "[1 rows x 30 columns]\n",
      "   humidity_1year  humidity_3days  humidity_2days  humidity_1days  \\\n",
      "0       97.375000       84.041667       90.708333       95.416667   \n",
      "1       96.291667       90.708333       95.416667       84.333333   \n",
      "\n",
      "   pressure_1year  pressure_3days  pressure_2days  pressure_1days  \\\n",
      "0     1023.708333     1021.750000     1021.666667     1021.666667   \n",
      "1     1019.458333     1021.666667     1021.666667     1007.625000   \n",
      "\n",
      "   temperature_1year  temperature_3days          ...           \\\n",
      "0         270.311755         275.364583          ...            \n",
      "1         270.466522         275.866250          ...            \n",
      "\n",
      "   wind_speed_1year  wind_speed_3days  wind_speed_2days  wind_speed_1days  \\\n",
      "0          1.666667          3.083333              2.25          1.750000   \n",
      "1          2.125000          2.250000              1.75          4.083333   \n",
      "\n",
      "   humidity.csv_today  pressure.csv_today  temperature.csv_today  \\\n",
      "0           84.333333         1007.625000             274.281250   \n",
      "1           71.833333         1014.583333             271.466667   \n",
      "\n",
      "   converted.csv_today  wind_direction.csv_today  wind_speed.csv_today  \n",
      "0             2.875000                134.583333              4.083333  \n",
      "1             2.708333                 38.333333              5.125000  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "   humidity_1year  humidity_3days  humidity_2days  humidity_1days  \\\n",
      "0       97.375000       84.041667       90.708333       95.416667   \n",
      "1       96.291667       90.708333       95.416667       84.333333   \n",
      "2       95.166667       95.416667       84.333333       71.833333   \n",
      "\n",
      "   pressure_1year  pressure_3days  pressure_2days  pressure_1days  \\\n",
      "0     1023.708333     1021.750000     1021.666667     1021.666667   \n",
      "1     1019.458333     1021.666667     1021.666667     1007.625000   \n",
      "2     1011.000000     1021.666667     1007.625000     1014.583333   \n",
      "\n",
      "   temperature_1year  temperature_3days          ...           \\\n",
      "0         270.311755         275.364583          ...            \n",
      "1         270.466522         275.866250          ...            \n",
      "2         272.664301         274.367083          ...            \n",
      "\n",
      "   wind_speed_1year  wind_speed_3days  wind_speed_2days  wind_speed_1days  \\\n",
      "0          1.666667          3.083333          2.250000          1.750000   \n",
      "1          2.125000          2.250000          1.750000          4.083333   \n",
      "2          1.791667          1.750000          4.083333          5.125000   \n",
      "\n",
      "   humidity.csv_today  pressure.csv_today  temperature.csv_today  \\\n",
      "0           84.333333         1007.625000             274.281250   \n",
      "1           71.833333         1014.583333             271.466667   \n",
      "2           49.750000         1025.333333             268.742083   \n",
      "\n",
      "   converted.csv_today  wind_direction.csv_today  wind_speed.csv_today  \n",
      "0             2.875000                134.583333              4.083333  \n",
      "1             2.708333                 38.333333              5.125000  \n",
      "2             3.000000                 58.750000              4.875000  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "   humidity_1year  humidity_3days  humidity_2days  humidity_1days  \\\n",
      "0       97.375000       84.041667       90.708333       95.416667   \n",
      "1       96.291667       90.708333       95.416667       84.333333   \n",
      "2       95.166667       95.416667       84.333333       71.833333   \n",
      "3       95.583333       84.333333       71.833333       49.750000   \n",
      "\n",
      "   pressure_1year  pressure_3days  pressure_2days  pressure_1days  \\\n",
      "0     1023.708333     1021.750000     1021.666667     1021.666667   \n",
      "1     1019.458333     1021.666667     1021.666667     1007.625000   \n",
      "2     1011.000000     1021.666667     1007.625000     1014.583333   \n",
      "3     1004.416667     1007.625000     1014.583333     1025.333333   \n",
      "\n",
      "   temperature_1year  temperature_3days          ...           \\\n",
      "0         270.311755         275.364583          ...            \n",
      "1         270.466522         275.866250          ...            \n",
      "2         272.664301         274.367083          ...            \n",
      "3         272.887275         274.281250          ...            \n",
      "\n",
      "   wind_speed_1year  wind_speed_3days  wind_speed_2days  wind_speed_1days  \\\n",
      "0          1.666667          3.083333          2.250000          1.750000   \n",
      "1          2.125000          2.250000          1.750000          4.083333   \n",
      "2          1.791667          1.750000          4.083333          5.125000   \n",
      "3          1.916667          4.083333          5.125000          4.875000   \n",
      "\n",
      "   humidity.csv_today  pressure.csv_today  temperature.csv_today  \\\n",
      "0           84.333333         1007.625000             274.281250   \n",
      "1           71.833333         1014.583333             271.466667   \n",
      "2           49.750000         1025.333333             268.742083   \n",
      "3           56.416667         1026.375000             268.240833   \n",
      "\n",
      "   converted.csv_today  wind_direction.csv_today  wind_speed.csv_today  \n",
      "0             2.875000                134.583333              4.083333  \n",
      "1             2.708333                 38.333333              5.125000  \n",
      "2             3.000000                 58.750000              4.875000  \n",
      "3             2.958333                 60.000000              3.958333  \n",
      "\n",
      "[4 rows x 30 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-0ffcd3edf39d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevin_cities\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_test_df_for_city\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-82c5c804ce06>\u001b[0m in \u001b[0;36mcreate_test_df_for_city\u001b[1;34m(city)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mcity_date_combos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_date_city_combo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_date_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcity_date\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcity_date_combos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_df_for_city_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-90-d86abfbba661>\u001b[0m in \u001b[0;36mcreate_data_df_for_city_date\u001b[1;34m(df, city_name, date)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0matrrib_df\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattrib_dfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# add the new tuple to the end of the list (row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mattrib_1yr_3days_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_1yr_3days_attrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matrrib_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattrib_1yr_3days_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mnew_data_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-34542d7da047>\u001b[0m in \u001b[0;36mget_1yr_3days_attrib\u001b[1;34m(city_name, date, attrib_df)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mday_1_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_avg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrib_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_1_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-93-909155831b43>\u001b[0m in \u001b[0;36mget_avg\u001b[1;34m(dataframe, city, date)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mstrdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdaily\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#create dataframe of just datetimes and that city\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdaily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdaily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m#filter above dataframe for a specific day\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mvalGood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalGood\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#create list of all temps for that day\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mcontains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m         result = str_contains(self._data, pat, case=case, flags=flags, na=na,\n\u001b[1;32m-> 1567\u001b[1;33m                               regex=regex)\n\u001b[0m\u001b[0;32m   1568\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[1;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0muppered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muppered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[1;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;31m# should really _check_ for NA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_map\u001b[1;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mconvert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    254\u001b[0m                           stacklevel=3)\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main - test creating df:\n",
    "'''\n",
    "create_all_attrib_models('Vancouver')'''\n",
    "\n",
    "for city in devin_cities:\n",
    "    test_df = create_test_df_for_city(city)\n",
    "    test_df.to_csv(city + '_test.csv', sep = ',', index=False)\n",
    "    print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
